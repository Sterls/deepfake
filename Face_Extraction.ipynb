{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each video was separated into frames. The face_recognition library was used to detect faces in each frame (if any). Upon detecting a face, the coordinates of the face + some padding was used to extract the face from the frame as a new image. These images were both stored in a folder named \"Real\" or \"Fake\" based on the type of video from which it was extracted, as well as, a pandas dataframe was built to hold the name of each image and the associated label. Some percentage of videos are used for training a classifier, while the remainder is used to validate the performance of the classifier. This distinction is made via a change to the path where the images are stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import Video\n",
    "from IPython.display import HTML\n",
    "from PIL import Image\n",
    "\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dir = 'Real/'\n",
    "real_video_files = [real_dir + x for x in os.listdir(real_dir)]\n",
    "\n",
    "fake_dir = 'Fake/'\n",
    "fake_video_files = [fake_dir + x for x in os.listdir(fake_dir)]\n",
    "\n",
    "#It may be worth extracting some padding around the face\n",
    "padding = 40\n",
    "\n",
    "image_num = 100000\n",
    "data = []\n",
    "path = 'Images/Train/Real'\n",
    "\n",
    "train_percentage = 0.5\n",
    "#Extract images of the faces in the real videos and pair the name of each image \n",
    "#with the word \"Real\"\n",
    "for vid_index in range(len(real_video_files)):\n",
    "    if vid_index> len(real_video_files)*train_percentage:\n",
    "        path = 'Images/Val/Real'\n",
    "    video_file = real_video_files[vid_index]\n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    frames = []\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True:\n",
    "            frames.append(frame)\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    #Extract every 20th frame\n",
    "    frames = frames[0::20]\n",
    "    for frame in frames:\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "    \n",
    "        #If no face is found in the frame, move on.\n",
    "        if len(face_locations) == 0:\n",
    "            continue\n",
    "\n",
    "        top, right, bottom, left = face_locations[0]\n",
    "        frame_face = frame[top-padding:bottom+padding, left-padding:right+padding]\n",
    "        image = cv.cvtColor(frame_face, cv.COLOR_BGR2RGB)\n",
    "        image_name = '{}.jpg'.format(image_num)\n",
    "        image_num += 1\n",
    "        #cv.imwrite(image_name,image)\n",
    "        cv.imwrite(os.path.join(path , image_name),image)\n",
    "        data.append([image_name,'Real'])\n",
    "    \n",
    "\n",
    "#Extract images of the faces in the fake videos and pair the name of each image \n",
    "#with the word \"Fake\"\n",
    "path = 'Images/Train/Fake'\n",
    "for vid_index in range(len(fake_video_files)):\n",
    "    if vid_index > len(fake_video_files)*train_percentage:\n",
    "        path = 'Images/Val/Fake'\n",
    "    video_file = fake_video_files[vid_index]\n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    frames = []\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True:\n",
    "            frames.append(frame)\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    #Extract every 20th frame\n",
    "    frames = frames[0::20]\n",
    "    for frame in frames:\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "    \n",
    "        #If no face is found in the frame, move on.\n",
    "        if len(face_locations) == 0:\n",
    "            continue\n",
    "\n",
    "        top, right, bottom, left = face_locations[0]\n",
    "        frame_face = frame[top-padding:bottom+padding, left-padding:right+padding]\n",
    "        image = cv.cvtColor(frame_face, cv.COLOR_BGR2RGB)\n",
    "        image_name = '{}.jpg'.format(image_num)\n",
    "        image_num += 1\n",
    "        #cv.imwrite(image_name,image)\n",
    "        cv.imwrite(os.path.join(path , image_name),image)\n",
    "        data.append([image_name,'Fake'])\n",
    "    \n",
    "\n",
    "#Build a pandas dataframe with the image name and the type of image (real/fake)\n",
    "#This will not be used in the current iteration but may be useful for further experiments\n",
    "dataset = pd.DataFrame(data,columns=['Image','Type'])    \n",
    "dataset.to_csv(\"full_dataset2.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Alternately, images can be extracted to one directory and \n",
    "the image name + label can be stored in a csv as shown in the comments below.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''real_dir = 'Real/'\n",
    "real_video_files = [real_dir + x for x in os.listdir(real_dir)]\n",
    "\n",
    "fake_dir = 'Fake/'\n",
    "fake_video_files = [fake_dir + x for x in os.listdir(fake_dir)]\n",
    "\n",
    "#It may be worth extracting some padding around the face\n",
    "padding = 0\n",
    "\n",
    "image_num = 0\n",
    "data = []\n",
    "path = 'Images/'\n",
    "\n",
    "val_split = 0.25\n",
    "#Extract images of the faces in the real videos and pair the name of each image \n",
    "#with the word \"Real\"\n",
    "for video_file in real_video_files:\n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    frames = []\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True:\n",
    "            frames.append(frame)\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    for frame in frames:\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "    \n",
    "        #If no face is found in the frame, move on.\n",
    "        if len(face_locations) == 0:\n",
    "            continue\n",
    "\n",
    "        top, right, bottom, left = face_locations[0]\n",
    "        frame_face = frame[top-padding:bottom+padding, left-padding:right+padding]\n",
    "        image = cv.cvtColor(frame_face, cv.COLOR_BGR2RGB)\n",
    "        image_name = '{}.jpg'.format(image_num)\n",
    "        image_num += 1\n",
    "        #cv.imwrite(image_name,image)\n",
    "        cv.imwrite(os.path.join(path , image_name),image)\n",
    "        data.append([image_name,'Real'])\n",
    "    \n",
    "\n",
    "#Extract images of the faces in the fake videos and pair the name of each image \n",
    "#with the word \"Fake\"\n",
    "for video_file in fake_video_files:\n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    frames = []\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True:\n",
    "            frames.append(frame)\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    for frame in frames:\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "    \n",
    "        #If no face is found in the frame, move on.\n",
    "        if len(face_locations) == 0:\n",
    "            continue\n",
    "\n",
    "        top, right, bottom, left = face_locations[0]\n",
    "        frame_face = frame[top-padding:bottom+padding, left-padding:right+padding]\n",
    "        image = cv.cvtColor(frame_face, cv.COLOR_BGR2RGB)\n",
    "        image_name = '{}.jpg'.format(image_num)\n",
    "        image_num += 1\n",
    "        #cv.imwrite(image_name,image)\n",
    "        cv.imwrite(os.path.join(path , image_name),image)\n",
    "        data.append([image_name,'Fake'])\n",
    "    \n",
    "\n",
    "#Build a pandas dataframe with the image name and the type of image (real/fake)\n",
    "dataset = pd.DataFrame(data,columns=['Image','Type'])   \n",
    "dataset.to_csv(\"full_dataset.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
